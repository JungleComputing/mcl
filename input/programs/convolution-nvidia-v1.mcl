/*
 * Copyright 2014 Pieter Hijma
 *
 * This file is part of MCL.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */



module convolution


import gpu;
import nvidia;





nvidia void convolve(const int outputHeight = 4096, const int outputWidth = 4096, const int 
        filterHeight = 9, const int filterWidth = 9, float[outputHeight,outputWidth] 
        output, const float[outputHeight + filterHeight / 2 * 2,outputWidth + 
        filterWidth / 2 * 2] input, const float[filterHeight,filterWidth] 
        filter) {
    const int tyleHeight = 4;
    const int tyleWidth = 2;
    const int nrThreadsX = 32;
    const int nrThreadsY = 16;
    const int nrBlocksOutputHeight = outputHeight / (nrThreadsY * tyleHeight);
    const int nrBlocksOutputWidth = outputWidth / (nrThreadsX * tyleWidth);
    const int filterSize = filterWidth * filterHeight;
    const int fh = filterHeight / 2 * 2;
    const int fw = filterWidth / 2 * 2;
    const int ti_end = fh + nrThreadsY * tyleHeight;
    const int tj_end = fw + nrThreadsX * tyleWidth;
    foreach (const int bi in nrBlocksOutputHeight blocks) {
        foreach (const int bj in nrBlocksOutputWidth blocks) {
            shared float[filterHeight,filterWidth] f;
            f as float[filterSize] f2;
            filter as float[filterSize] filter2;
            shared float[ti_end,tj_end] data;
            foreach (const int ti in nrThreadsY threads) {
                foreach (const int tj in nrThreadsX threads) {
                    const int yDataOffset = bi * (nrThreadsY * tyleHeight);
                    const int xDataOffset = bj * (nrThreadsX * tyleWidth);
                    const int j = xDataOffset + tj * tyleWidth;
                    const int i = yDataOffset + ti * tyleHeight;
                    local float[tyleHeight,tyleWidth] sum;
                    for (local int k = ti * nrThreadsX + tj; k < filterSize; k 
                            += nrThreadsX * nrThreadsY) {
                        f2[k] = filter2[k];
                    }
                    for (local int mti = ti; mti < ti_end; mti += nrThreadsY) {
                        for (local int mtj = tj; mtj < tj_end; mtj += 
                                nrThreadsX) {
                            data[mti,mtj] = input[yDataOffset + mti,xDataOffset 
                                    + mtj];
                        }
                    }
                    barrier(shared);
                    for (local int k = 0; k < tyleHeight; k++) {
                        for (local int l = 0; l < tyleWidth; l++) {
                            sum[k,l] = 0;
                        }
                    }
                    for (local int y = 0; y < filterHeight; y++) {
                        for (local int x = 0; x < filterWidth; x++) {
                            for (local int k = 0; k < tyleHeight; k++) {
                                for (local int l = 0; l < tyleWidth; l++) {
                                    sum[k,l] = sum[k,l] + f[y,x] * data[ti * 
                                            tyleHeight + y + k,tj * tyleWidth + 
                                            x + l];
                                }
                            }
                        }
                    }
                    for (local int k = 0; k < tyleHeight; k++) {
                        for (local int l = 0; l < tyleWidth; l++) {
                            output[i + k,j + l] = sum[k,l] / filterSize;
                        }
                    }
                }
            }
        }
    }
}


/*

INFO at |project://mcl/input/programs/convolution-nvidia-a-v1.mcl|(1343,7,<34,52>,<34,59>): using shared memory: Try to maximize the # blocks per SMP. This depends on the number of threads, amount of shared memory and the number of registers. Now using 2 of 8 blocks

better

convolveKernel           : avg = 11.4 ms, total =   57 ms, count =         5

#GFLOPS: 241.29 GFLOPS
Effective Bandwidth: 12.72 GB/s
Bandwidth: 10.986 GB/s



*/