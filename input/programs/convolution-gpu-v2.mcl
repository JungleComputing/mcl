/*
 * Copyright 2014 Pieter Hijma
 *
 * This file is part of MCL.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */



module convolution

import gpu;


gpu void convolve(const int outputHeight, const int outputWidth, const int 
        filterHeight, const int filterWidth, float[outputHeight,outputWidth] 
        output, const float[outputHeight + filterHeight / 2 * 2,outputWidth + 
        filterWidth / 2 * 2] input, const float[filterHeight,filterWidth] 
        filter) {

    const int filterSize = filterWidth * filterHeight;
    const int fh = filterHeight / 2 * 2;
    const int fw = filterWidth / 2 * 2;
    
    const int nrThreadsY = 32;
    const int nrThreadsX = 32;
    
    const int nrBlocksY = outputHeight / nrThreadsY;
    const int nrBlocksX = outputWidth / nrThreadsX;
    
    const int ti_end = fh + nrThreadsY;
	const int tj_end = fw + nrThreadsX;
    
    filter as float[filterSize] filter2;
    
    foreach (const int bi in nrBlocksY blocks) {  
        foreach (const int bj in nrBlocksX blocks) {       
        
        	local float[filterHeight, filterWidth] f;
        	f as float[filterSize] f2;
        	
        	local float [ti_end, tj_end] data;
        	
        	
        	foreach (const int ti in nrThreadsX threads) {
            	foreach (const int tj in nrThreadsY threads) {            
            
            		const int yDataOffset = bi * (nrThreadsY);
        			const int xDataOffset = bj * (nrThreadsX); 
					const int j = xDataOffset + tj;
					const int i = yDataOffset + ti;
            
            
	            	for (int k = ti * nrThreadsX + tj; k < filterSize; 
	            			k += nrThreadsX * nrThreadsY) {
		            	 f2[k] = filter2[k];
		            }
	            
	            	for (int mti = ti; mti < ti_end; mti += nrThreadsY) {
	            		for (int mtj = tj; mtj < tj_end; mtj += nrThreadsX) {
	            			data[mti, mtj] = input[yDataOffset + mti, xDataOffset + mtj];
	            		}
	            	}
	            
		            barrier(local);
            
            
	                float sum = 0.0;
	                for (int y = 0; y < filterHeight; y++) {               
	                    for (int x = 0; x < filterWidth; x++) {                  
	                        sum = sum + f[y,x] * data[ti + y,tj + x];
	                    }
	                }
	                output[i,j] = sum / (filterSize);
	            }
            }
        }
    }
}


/*


running pass getDataReuse
THIS SHOULD GO IN A MESSAGE, BUT NOT YET IMPLEMENTED:
THIS PASS IS APPROXIMATE!
{<"depends on loop",|project://mcl/input/programs/convolution-gpu-a-v2.mcl|(1116,2,<36,28>,<36,30>)>,<"depends on loop",|project://mcl/input/programs/convolution-gpu-a-v2.mcl|(1176,2,<37,32>,<37,34>)>}


INFO at |project://mcl/input/programs/convolution-gpu-a-v2.mcl|(2171,4,<62,46>,<62,50>): Data reuse: For data[i + y,j + x]:
  For dimension 0:
    the loops int y = 0, int x = 0 may have a positive data reuse ratio: filterHeight * filterWidth / (32 * bi + filterHeight)
  For dimension 1:
    the loops int y = 0, int x = 0 may have a positive data reuse ratio: filterHeight * filterWidth / (32 * bj + filterWidth)
INFO at |project://mcl/input/programs/convolution-gpu-a-v2.mcl|(1579,7,<47,24>,<47,31>): Data reuse: filter2[k] is accessed for nrBlocksY blocks bi.
INFO at |project://mcl/input/programs/convolution-gpu-a-v2.mcl|(1579,7,<47,24>,<47,31>): Data reuse: filter2[k] is accessed for nrBlocksX blocks bj.
INFO at |project://mcl/input/programs/convolution-gpu-a-v2.mcl|(1791,5,<52,33>,<52,38>): Data reuse: For input[yDataOffset + mti,xDataOffset + mtj]:
  For dimension 0:
    the loops const int bi, const int ti may have a positive data reuse ratio: outputHeight / (outputHeight - 31)
    the loops const int tj, int mti = ti may have a positive data reuse ratio: (filterHeight + 32) / (filterHeight + -1 * ti + 32)
    the loops const int bi, const int bj may have a positive data reuse ratio: outputHeight * outputWidth / (outputHeight - 31) / 1024
    the loops const int ti, int mti = ti may have a positive data reuse ratio: (filterHeight + 32) / (filterHeight + -1 * ti + 32)
    the loops const int bi, const int tj may have a positive data reuse ratio: outputHeight / (outputHeight - 31)
    the loops const int ti, const int tj  have a positive data reuse ratio: 1024
  For dimension 1:
    the loops const int ti, int mtj = tj may have a positive data reuse ratio: (filterWidth + 32) / (filterWidth + -1 * tj + 32)
    the loops const int tj, int mtj = tj may have a positive data reuse ratio: (filterWidth + 32) / (filterWidth + -1 * tj + 32)
    the loops const int bi, const int bj may have a positive data reuse ratio: outputHeight * outputWidth / (outputWidth - 31) / 1024
    the loops const int bj, const int tj may have a positive data reuse ratio: outputWidth / (outputWidth - 31)
    the loops const int ti, const int tj  have a positive data reuse ratio: 1024
    the loops const int bj, const int ti may have a positive data reuse ratio: outputWidth / (outputWidth - 31)

INFO at |project://mcl/input/programs/convolution-gpu-a-v2.mcl|(196,6,<8,8>,<8,14>): It may be beneficial to consider computing more than one element of output per thread.

convolveKernel           : avg = 24.1 ms, total =  121 ms, count =         5

#GFLOPS: 113.94 GFLOPS
Effective Bandwidth: 7.0414 GB/s
Bandwidth: 5.1876 GB/s



*/
