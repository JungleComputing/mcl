/*
 * Copyright 2014 Pieter Hijma
 *
 * This file is part of MCL.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */



module matrixmultiplication


import perfect;
import cpu;





cpu void matmul(const int n, const int m, const int p, float[n,m] c, const 
        float[n,p] a, const float[p,m] b) {
        
    int nrElsM = 8;
    int nrVectorsM = cpu.hierarchy.threads.thread.vectors.nr_units;
    int nrThreadsM = m / (nrElsM * nrVectorsM);
    
    int nrElsN = 8;
    int nrThreadsN = n / nrElsN;
    
    c as float[nrThreadsN, nrThreadsM][nrElsN, nrElsM][1, nrVectorsM] c2;
    a as float[nrThreadsN, p][nrElsN, 1] a2;
    b as float[p, nrThreadsM][1, nrElsM][1, nrVectorsM] b2;
    
    foreach (const int ti in nrThreadsN threads) {
        foreach (const int tj in nrThreadsM threads) {
            foreach (const int vj in nrVectorsM vectors) {
            	for (int ej = 0; ej < nrElsM; ej++) {
            		float[p] bTemp;
            		
            		for (int k = 0; k < p; k++) {
            			bTemp[k] = b2[k, tj][0, ej][0, vj];
            		}
            		
            		for (int ei = 0; ei < nrElsN; ei++) {
                		float sum = 0.0;
                		
		                for (int k = 0; k < p; k++) {
		                    sum += a2[ti,k][ei, 0] * bTemp[k];
		                }
		                c2[ti,tj][ei, ej][0, vj] += sum;
            		}
            	}
            }
        }
    }
}


/*

xeon_e5620

matmulKernel             : avg =  784 ms, total = 3.92  s, count =         5

#GFLOPS: 21.913 GFLOPS


INFO at |project://mcl/input/programs/mm_cpu-v2.mcl|(1168,5,<39,52>,<39,57>): Data reuse: bTemp[k] is accessed inside for-loop with index ei but does not depend on it.
INFO at |project://mcl/input/programs/mm_cpu-v2.mcl|(1150,2,<39,34>,<39,36>): Data reuse: a2[ti,k][ei,0] is accessed inside for-loop with index ej but does not depend on it.
INFO at |project://mcl/input/programs/mm_cpu-v2.mcl|(1150,2,<39,34>,<39,36>): Data reuse: a2[ti,k][ei,0] is accessed for nrVectorsM vectors vj.
INFO at |project://mcl/input/programs/mm_cpu-v2.mcl|(1150,2,<39,34>,<39,36>): Data reuse: a2[ti,k][ei,0] is accessed for nrThreadsM threads tj.
INFO at |project://mcl/input/programs/mm_cpu-v2.mcl|(906,2,<32,26>,<32,28>): Data reuse: b2[k,tj][0,ej][0,vj] is accessed for nrThreadsN threads ti.


From my experience with the xeon phi I know it is beneficial to reuse even more data from bTemp in this case.
Leading to mm_cpu-v3.

*/
