package matrixmultiplication;

module matrixmultiplication;

export matmul;

import gpu;

gpu void matmul(const int n, const int m, const int p, float[n,m] c, const 
        float[n,p] a, const float[p,m] b) {

    const int nrThreadsM = gpu.hierarchy.blocks.block.threads.max_nr_units;
    const int nrBlocksM = m / nrThreadsM;
    int nrLoadIters = p / nrThreadsM;
    
    foreach (const int i in n blocks) {
    
        foreach (const int bj in nrBlocksM blocks) {
        
	    local float[p] l_a as float[nrLoadIters][nrThreadsM] l_a2;
	    a as float[n, nrLoadIters][1, nrThreadsM] a2;
        
            foreach (const int tj in nrThreadsM threads) {
            
            	for (int l = 0; l < nrLoadIters; l++) {
		    l_a2[l][tj] = a2[i, l][0, tj];
            	}
            	
            	barrier(local);
            
                const int j = bj * nrThreadsM + tj;
                float sum = 0.0;
                for (int k = 0; k < p; k++) {
                
                    sum += l_a[k] * b[k,j];
                }
                c[i,j] += sum;
            }
        }
    }
}


/*
INFO at |project://mcl/input/programs/mm_gpu_v1.mcl|(110,1,<7,66>,<7,67>): It may be beneficial to consider computing more than one element of c per thread.
INFO at |project://mcl/input/programs/mm_gpu_v1.mcl|(995,1,<33,41>,<33,42>): Data reuse: b[k,j] is accessed for n blocks i.
INFO at |project://mcl/input/programs/mm_gpu_v1.mcl|(718,2,<24,28>,<24,30>): Data reuse: a2[i,l][0,tj] is accessed for nrBlocksM blocks bj.


matmulKernel             : avg =  172 ms, total =  860 ms, count =         5

#GFLOPS: 99.852 GFLOPS
Effective Bandwidth: 186.26 GB/s
Bandwidth: 0.27245 GB/s



hd7970

matmulKernel             : avg = 59.9 ms, total =  299 ms, count =         5

#GFLOPS: 286.9 GFLOPS



*/

